---
title: Data Science Interview Questions
author: Ben Ewing
slug: data-science-interview-questions
categories:
  - technical
tags: []
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>I’ve seen a number of articles/posts pop up around the internet with lists of data science interview questions. I thought it might be a good exercise in communication and data science knowledge to answer these questions. I am finding it harder than I would have expected to write good (and hopefully useful) answers!</p>
<p>Question sources:</p>
<ul>
<li><a href="https://hackernoon.com/160-data-science-interview-questions-415s3y2a">HackerNoon - 160+ Data Science Interview Questions</a></li>
</ul>
<p>Additional resources:</p>
<ul>
<li><a href="http://alexeygrigorev.com/">Alexey Grigorev</a> has put together a whole GitHub repo with data science interview questions <em>and</em> answers, <a href="https://github.com/alexeygrigorev/data-science-interviews/">available here</a>. He also has his own extensive collection of <a href="https://github.com/alexeygrigorev/data-science-interviews/blob/master/awesome.md">resources</a>.</li>
<li><a href="https://chrisalbon.com/">Chris Albon</a> has a collection of machine learning flashcards, <a href="https://machinelearningflashcards.com/">available as a whole set for a price</a>, or sporadically posted <a href="https://twitter.com/chrisalbon">on his Twitter feed</a>. I’ve found these to be a useful way to identify gaps in my knowledge.</li>
</ul>
</div>
<div id="supervised-machine-learning" class="section level2">
<h2>Supervised machine learning</h2>
<div id="what-is-supervised-machine-learning" class="section level3">
<h3>What is supervised machine learning?</h3>
<p>Supervised machine learning is when we use a dataset, <span class="math inline">\(X\)</span>, to predict some known target value <span class="math inline">\(y\)</span> where <span class="math inline">\(y\)</span> might be a label/class or some continuous value. In unsupervised learning we learn about a dataset <span class="math inline">\(X\)</span> without any label, for example clustering individuals.</p>
</div>
</div>
<div id="linear-regression" class="section level2">
<h2>Linear Regression</h2>
<div id="what-is-regression-which-models-can-you-use-to-solve-a-regression-problem" class="section level3">
<h3>What is regression? Which models can you use to solve a regression problem?</h3>
<p>In a regression problem we predict a continuous value (rather than a label). Linear regression is very common; it can be augmented with polynomial features or regularization terms (lasso and ridge regression). Many other algorithms can also be used for regression problems, such as random forests with regression trees.</p>
</div>
<div id="what-is-linear-regression-when-do-we-use-it" class="section level3">
<h3>What is linear regression? When do we use it?</h3>
<p>For data <span class="math inline">\(X\)</span>, observation <span class="math inline">\(i\)</span>, a linear regression predicts a value <span class="math inline">\(y_i = x_i^T\beta\)</span> for a set of coefficients <span class="math inline">\(\beta\)</span>. We typically assume there to be some error term <span class="math inline">\(\epsilon_i\)</span> that is normally distributed around 0.</p>
<p>Additional notes:</p>
<ul>
<li><p>We can add an extra column of 1s to the data to include an intercept term. The column of 1s allows us to add an extra <span class="math inline">\(\beta_0\)</span> which (in the case of linear regression with a single variable) changes where on the y-axis the line passes through. Without this term the line will just pass through 0.</p></li>
<li><p>The ‘linear’ in linear regression refers to the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(\beta\)</span>, the <span class="math inline">\(x_i\)</span>’s can be polynomials, as in the case of polynomial regression.</p></li>
<li><p>While the <span class="math inline">\(\beta\)</span>’s can be found through a number of techniques, choosing <span class="math inline">\(\beta\)</span> to minimize <span class="math inline">\((y- X\beta)^T(y- X\beta)\)</span> (as is very common, this is just ordinary least squares) gives a very elegant closed form: <span class="math inline">\(\hat{\beta} = (X^TX)^{-1}X^Ty\)</span>.</p></li>
</ul>
</div>
<div id="whats-the-normal-distribution-why-do-we-care-about-it" class="section level3">
<h3>What’s the normal distribution? Why do we care about it?</h3>
<p>The normal distribution with with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> as <span class="math inline">\(p(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)}\)</span>.</p>
<p>There are a lot of reasons to care about the normal distribution (e.g. Alexey talks about the central limit theorem for this question). Perhaps the reason the normal distribution pops up everywhere is that it’s kernel (with known variance) is just the squared difference between two quantities, which we use quite often.</p>
</div>
<div id="how-do-we-check-if-a-variable-follows-the-normal-distribution" class="section level3">
<h3>How do we check if a variable follows the normal distribution?</h3>
<p>For exploratory data analysis (EDA) I would just plot a histogram or the empirical density. For a more formal setting one could look at the skew and kurtosis (both 0 for a normal distribution), or run any one of the many <a href="https://en.wikipedia.org/wiki/Normality_test">normality tests</a>.</p>
<p>This is a pretty common procedure when looking at regression residuals, remember we want a normal error!</p>
</div>
<div id="what-if-we-want-to-build-a-model-for-predicting-prices-are-prices-distributed-normally-do-we-need-to-do-any-pre-processing-for-prices" class="section level3">
<h3>What if we want to build a model for predicting prices? Are prices distributed normally? Do we need to do any pre-processing for prices?</h3>
<p>My best guess (i.e. based on only my priors, no data) is that prices are not normally distributed, in fact I would expect the distribution of prices to be very skewed due to the presence of high-end luxury goods. We can deal with this by using a log-transformation on the data. I assume this question is not asking about pre-processing like converting to the same currency or other data cleaning steps.</p>
</div>
<div id="what-are-the-methods-for-solving-linear-regression-do-you-know" class="section level3">
<h3>What are the methods for solving linear regression do you know?</h3>
<p>See my answer for “What is linear regression? When do we use it?” for the closed form approach (and where it comes from), but note that we can also use any(?) gradient-based optimization approach as well.</p>
</div>
</div>
<div id="what-is-gradient-descent-how-does-it-work" class="section level2">
<h2>What is gradient descent? How does it work?</h2>
<p>Gradient descent a calculus-based optimizatin method that iteratively updates parameters in a model in the opposite direction of the gradient. For a linear regression model gradient descent looks something like this: <span class="math inline">\(\mathbf{\beta}_{i+1} = \mathbf{\beta}_i -\alpha\nabla_\beta(\mathbf{X}^T\mathbf{\beta}_i - \mathbf{y})^2\)</span> where <span class="math inline">\(\alpha\)</span> is the learning rate (this controls the size of each update).</p>
<p>Note that a gradient is just a multivaraite derivative, so if we have a linear model <span class="math inline">\(\beta_0 + \beta_1x_1\)</span> the gradient with respect to the betas is <span class="math inline">\([1, x]^T\)</span>. <a href="https://ruder.io/optimizing-gradient-descent/index.html">Sebastian Ruder</a> has a really great overview oof gradient-based optimization methods.</p>
<div id="what-is-the-normal-equation" class="section level3">
<h3>What is the normal equation?</h3>
<p>I think this is a silly interview question. A <span class="math inline">\(N(\mu, \sigma^2)\)</span> distribution has PDF <span class="math inline">\(\frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left[-\frac{1}{2\sigma^2}(x-\mu)^2\right]}\)</span>.</p>
</div>
<div id="what-is-sgd-whats-the-difference-with-the-usual-gradient-descent" class="section level3">
<h3>What is SGD? What’s the difference with the usual gradient descent?</h3>
<p>In “standard” (i.e. Batch) gradient descent we use all of the data at once, but this is computationally infeasible for sufficiently large datasets. Stochastic Gradient Descent randomly shuffles the data and then performs gradient descent one observation at a time to allow for computationally efficient updates. This approach can also be combined with the minibatch approach, where gradient descent is applied to smaller (computationally feasible) subsets of the data.</p>
</div>
<div id="which-metrics-for-evaluating-regression-models-do-you-know" class="section level3">
<h3>Which metrics for evaluating regression models do you know?</h3>
<p>This is also kind of a silly question, what do you want to know about the model? There are goodness-of-fit measures like R-squared, measures of prediction accuracy like MSE, RMSE (next question), and heuristics that can be used to choose from many models like AIC and BIC. There are surely <em>many</em> other ways to evaluate a linear model.</p>
</div>
<div id="what-are-mse-and-rmse" class="section level3">
<h3>What are MSE and RMSE?</h3>
<ul>
<li>Mean Squared Error is the squared difference between a prediction and its true value: <span class="math inline">\(\frac{1}{n}\sum_i^n(y_i - \hat{y}_i)^2\)</span>.</li>
<li>Root Mean Squared Error is the square-root of the MSE. The rescaling just allows us to talk about the error using the same units as the dependent variable, for example:</li>
</ul>
<pre class="r"><code># R

y &lt;- 5
y_hat &lt;- 2

paste0(&quot;MSE: &quot;, mean((y - y_hat)^2), 
       &quot;; RMSE: &quot;, mean((y - y_hat)^2)^0.5)</code></pre>
<pre><code>## [1] &quot;MSE: 9; RMSE: 3&quot;</code></pre>
</div>
</div>
<div id="coding" class="section level2">
<h2>Coding</h2>
<div id="implement-ols-linear-regression" class="section level3">
<h3>Implement OLS Linear Regression</h3>
<p>Some data, note that the outcome really is a linear function of the input! Also note that no intercept is needed.</p>
<pre class="r"><code># R

n &lt;- 1000
x &lt;- matrix(c(rnorm(n), rnorm(n, mean = 1), rnorm(n, sd = 3)),
            nrow = n)
y &lt;- x[ , 1]*0.5 + x[ , 2]*0.25 + x[ , 3]*3</code></pre>
<p>In OLS we assume our outoome is the product of some linear model (as it is in the example data above), and we seek to minimize the squared distance between our predictions, <span class="math inline">\(X^T\beta\)</span>, and the true value <span class="math inline">\(y\)</span>. In matrix form we want to minimze <span class="math inline">\((y- X\beta)^T(y- X\beta)\)</span>. Take the derivative with respect to <span class="math inline">\(\Beta\)</span>, set it equal to 0, solve for <span class="math inline">\(\beta\)</span> (with the assumption that <span class="math inline">\(X\)</span> is invertible), and you end up with <span class="math inline">\(\beta_{OLS} = (X^TX)^{-1}X^Ty\)</span>.</p>
<p>This is an easy closed-form equation to implement in any language, assuming the interviewer doesn’t require the interviewee to implement their own matrix inversion function.</p>
<pre class="r"><code># R

bens_lm &lt;- function(x, y) {
  solve((t(x) %*% x)) %*% (t(x) %*% y) 
}
bens_lm(x, y)</code></pre>
<pre><code>##      [,1]
## [1,] 0.50
## [2,] 0.25
## [3,] 3.00</code></pre>
<p>Compare with R’s linear model.</p>
<pre class="r"><code># R

lm(y ~ x)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)           x1           x2           x3  
##   1.078e-15    5.000e-01    2.500e-01    3.000e+00</code></pre>
</div>
<div id="implement-logistic-regression" class="section level3">
<h3>Implement Logistic Regression</h3>
<pre class="python"><code># Python</code></pre>
</div>
<div id="implement-a-perceptron" class="section level3">
<h3>Implement a Perceptron</h3>
</div>
<div id="implement-a-decision-tree" class="section level3">
<h3>Implement a Decision Tree</h3>
</div>
<div id="implement-adaboost" class="section level3">
<h3>Implement AdaBoost</h3>
</div>
</div>
